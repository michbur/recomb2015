\documentclass[final]{beamer}
\usepackage{grffile}
\mode<presentation>{\usetheme{CambridgeUSPOL}}

\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{array,booktabs,tabularx}
\newcolumntype{Z}{>{\centering\arraybackslash}X}

% rysunki
\usepackage{tikz}
\usepackage{ifthen}
\usepackage{xxcolor}
\usetikzlibrary{arrows}
\usetikzlibrary[topaths]
\usetikzlibrary{decorations.pathreplacing}
%\usepackage{times}\usefonttheme{professionalfonts}  % times is obsolete
\usefonttheme[onlymath]{serif}
\boldmath
\usepackage[orientation=portrait,size=a0,scale=1.4,debug]{beamerposter}                       % e.g. for DIN-A0 poster
%\usepackage[orientation=portrait,size=a1,scale=1.4,grid,debug]{beamerposter}                  % e.g. for DIN-A1 poster, with optional grid and debug output
%\usepackage[size=custom,width=200,height=120,scale=2,debug]{beamerposter}                     % e.g. for custom size poster
%\usepackage[orientation=portrait,size=a0,scale=1.0,printer=rwth-glossy-uv.df]{beamerposter}   % e.g. for DIN-A0 poster with rwth-glossy-uv printer check
% ...
%

\usecolortheme{seagull}
\useinnertheme{rectangles}
\setbeamercolor{item projected}{bg=darkred}
% \setbeamertemplate{enumerate items}[default]
\setbeamertemplate{caption}{\insertcaption} 
\setbeamertemplate{navigation symbols}{}
\setbeamercovered{transparent}
\setbeamercolor{block title}{fg=darkred}
\setbeamercolor{local structure}{fg=darkred}

\setbeamercolor*{enumerate item}{fg=darkred}
\setbeamercolor*{enumerate subitem}{fg=darkred}
\setbeamercolor*{enumerate subsubitem}{fg=darkred}

\setbeamercolor*{itemize item}{fg=darkred}
\setbeamercolor*{itemize subitem}{fg=darkred}
\setbeamercolor*{itemize subsubitem}{fg=darkred}

\newlength{\columnheight}
\setlength{\columnheight}{93cm}
\renewcommand{\thetable}{}
\def\andname{,}
\authornote{}

\renewcommand{\APACrefatitle}[2]{}
\renewcommand{\bibliographytypesize}{\footnotesize} 
\renewcommand{\APACrefYearMonthDay}[3]{%
  {\BBOP}{#1}
  {\BBCP}
}

\begin{document}



<<knitrIntro, echo = FALSE, message=FALSE>>=
library(xtable)
library(ggplot2)
library(reshape2)
library(biogram)
library(grid)
load("three_n_power.RData")

poster_theme <- theme(plot.background=element_rect(fill = "transparent",
                                                   colour = "transparent"),
                      plot.margin = unit(c(1,1,1,1), "cm"),
                      axis.text.x = element_text(size=17), 
                      axis.text.y = element_text(size=17),
                      axis.title.x = element_text(size=20, vjust = -1), 
                      axis.title.y = element_text(size=20, vjust = 1),
                      strip.text = element_text(size=20),
                      legend.text = element_text(size=17), 
                      legend.title = element_text(size=20),
                      plot.title = element_text(size=28),
                      panel.background = element_rect(fill = "transparent",colour = "black"),
                      legend.background = element_rect(fill="NA"))
@


\date{}
\author{Piotr Sobczyk\inst{1}*, Micha\l{}  Burdukiewicz\inst{2}, Chris Lauber\inst{3}, Pawe\l{} Mackiewicz\inst{2} \\
*Piotr.Sobczyk@pwr.edu.pl}


\institute{\small{

\textsuperscript{1}Wroc\l{}aw University of Technology, Department of Mathematics, Poland

\vspace{0.3cm}

\textsuperscript{2}University of Wroc\l{}aw, Department of Genomics, Poland 

\vspace{0.3cm}

\textsuperscript{3}Dresden University of Technology, Institute of Medical Informatics and Biometry, Poland 

}}
\title{\huge Quick Permutation Test: feature filtering of n-gram data}

\begin{frame}
  \begin{columns}
    \begin{column}{.47\textwidth}
      \begin{beamercolorbox}[center,wd=\textwidth]{postercolumn}
        \begin{minipage}[T]{.95\textwidth}
          \parbox[t][\columnheight]{\textwidth}
            {
    
        
    \begin{block}{Introduction}
N-grams (k-tuples) are vectors of n characters derived from input sequence(s). They may form continuous sub-sequences or be discontinuous. 
Important n-gram parameter is its position. Instead of just counting n-grams, one may want to count how many n-grams occur at a given position in multiple (e.g. related) sequences.

Originally developed for natural language processing, n-grams are also used in genomics~\citep{fang2011}, transcriptomics~\citep{wang2014} and proteomics~\citep{guo2014}.

\small{
       \begin{columns}[c] % the "c" option specifies center vertical alignment
    \column{.5\textwidth} 
<<echo = FALSE,message=FALSE,results='asis'>>=
tfres <- function(x, cn = c("1-ngram", "2-gram", "3-gram"),
                  rn = round(seq(from = 0.25, to = 0.91, length.out = 6), 2)) {
  colnames(x) <- cn
  rownames(x) <- rn
  x <- melt(x)
  #significant proportion, ngram, value
  colnames(x) <- c("sig", "ngram", "value")
  x[["sig"]] <- as.factor(x[["sig"]])
  x
}
  

sample_seq <- matrix(sample(1L:4, 18, replace = TRUE), nrow = 3)
colnames(sample_seq) <- paste0("P", 1L:ncol(sample_seq))
rownames(sample_seq) <- paste0("S", 1L:nrow(sample_seq))
print(xtable(data.frame(sample_seq), caption = "Sample sequences.", digits = 0))

# unis <- count_ngrams(sample_seq, 1, 1L:4, pos = TRUE)
# unis <- data.frame(as.matrix(unis))[, 1L:7]
# print(xtable(unis, caption = "A fraction of possible unigrams with position information.", digits = 0), include.rownames = FALSE)
@
      
      
     % column designated by a command

    \column{.5\textwidth}
    
<<echo = FALSE,message=FALSE,results='asis'>>=
    
     unis <- count_ngrams(sample_seq, 1, 1L:4)
unis <- data.frame(as.matrix(unis))
colnames(unis) <- 1L:4
print(xtable(unis, caption = "Unigram counts.", digits = 0), include.rownames = FALSE)
@

    \end{columns}

<<echo = FALSE,message=FALSE,results='asis'>>=
    
unis <- count_ngrams(sample_seq, 1, 1L:4, pos = TRUE)
unis <- data.frame(as.matrix(unis))[, 1L:13]
colnames(unis) <- substr(sub("X", "P", colnames(unis)), 0, 4)
print(xtable(unis, caption = "A fraction of possible unigrams with position information.", digits = 0), include.rownames = FALSE)
@
}    
    \end{block}
    
    \vfill
    
    \begin{block}{Curse of dimensionality}
    
Even when we limit ourselves to only continuous positioned n-grams, build on $m$ possible
characters, feature space growths rapidly with the number of elements in n-gram
($n$) and the length of the sequence ($L$).    
    
The number of possible positioned n-grams: 

\begin{center}
\scalebox{0.85}{
$
n_{\text{max}} = L \times m^n
$
}

\\


\scalebox{0.85}{  
<<echo = FALSE,message=FALSE,fig.align='center',fig.width=14>>=
library(reshape2)
n <- 1:6
n_max <- 4^n

dat <- melt(sapply(2:5*5, function(i) i * n_max))
dat[["Var2"]] <- factor(dat[["Var2"]])
levels(dat[["Var2"]]) <- 2:5*5
colnames(dat) <- c("n", "L", "n_max")
ggplot(dat, aes(x = n, y = n_max, fill = L, col = L)) + 
  geom_line(linetype="dotted", size=1.5) + 
  geom_point(size=7, shape=21) +
  scale_x_continuous(breaks = 0L:6) +
  scale_y_continuous(expression(n["max"])) +
  poster_theme

@
}
\end{center}
    \end{block}
    \vfill
    
    
    \begin{block}{Feature selecting permutation tests}
    Model and statistic independent permutation tests can be used to filter features obtained through counting n-grams.
    
    During a permutation test class labels are randomly exchanged during computation of a significance statistic. p-values are defined as:
    
\begin{center}
\scalebox{0.85}{
$      
\textnormal{p-value} = \frac{N_{T_P > T_R}}{N}
$
}
\end{center}

where $N_{T_P > T_R}$ is number of times when $T_P$ (permuted test statistic) was more extreme than $T_R$ (test statistic for non-permuted data).

Permutation tests are computationally expensive (especially considering precise estimation of low p-values, because the number of permutations is inversely proportional to the interval between p-values).
      
    \end{block}
    \vfill
    
    
\begin{block}{QuiPT concept}

In each permutation, for every observation, there are four possible results.

\begin{center}
\scalebox{0.85}{
$P(Target, Feature) = (1,1)) = p \cdot q$
}
\end{center}

\\

\begin{center}
\scalebox{0.85}{
$P(Target, Feature) = (1,0)) = p \cdot (1-q)$
}
\end{center}

\\

\begin{center}
\scalebox{0.85}{
$P(Target, Feature) = (0,1)) = (1-p) \cdot q$
}
\end{center}

\\

\begin{center}
\scalebox{0.85}{
$P(Target, Feature) = (0,0)) = (1-p) \cdot (1-q)$
}
\end{center}

\\

Where $p$ and $q$ are fractions of positive observations in target and
feature respectively. An another view at permutation test is therefore that we 
get a contingency table, which is to be tested for independence.
Computing probability of a such table with two constraints, $n_{1,\cdot} = n_{1,1} + n_{1,0}$ and
$n_{\cdot, 1} = n_{1,1} + n_{0,1}$, and 
conditioning on $n_{1,1}$, leads to hypergeometric distribution.
$n_{i,j}$ denotes number of observations for which 
\scalebox{0.85}{$(Target, Feature) = (i,j)$}

This is in fact exact two-sided Fisher's test~\citep{lehmann1986testing}. 
%Information Gain is a way of deciding how strong is the evidence against independance.

\end{block}
\vfill 
    
    }
        \end{minipage}
      \end{beamercolorbox}
    \end{column}
    
    
%new column ------------------------------------------------------    
    
    \begin{column}{.54\textwidth}
      \begin{beamercolorbox}[center,wd=\textwidth]{postercolumn}
        \begin{minipage}[T]{.95\textwidth}  
          \parbox[t][\columnheight]{\textwidth}
            {
     

 
\begin{block}{Computational cost}

The cost of performing QuiPT is equal to computing a test statistic and 
probability of occurence for $n_{1,1} + n_{0,1}$ contingency tables.

Suppose we consider 6-grams build on sequences of length 25 build of four 
characters. Then there are around 100,000 n-grams (features) to test. 
This means that for Benjamini-Hochberg procedure, we need to calculate 
p-values with accuracy of $0.05 \times 10^{-5}$. This requires at least 
2 million permutations. Each permutation, apart from reshuffling labels, 
requires computation of a test statistic. Since n-gram features are very sparse vectors, QuiPT needs to evaluate only few contingency tables.

The relative difference in speed between QuiPT and normal permutation tests depends on several factors, as a number of permutations and input data. For example, for simulation scheme presented below, QuiPT was on average 93 times faster than normal permutation test with $10^5$ permutations.
\end{block}
\vfill 
    
    \begin{block}{Contingency table representation}
    
    
    \begin{columns}
    \centering
    \column{.5\textwidth} 
    \scalebox{1}{
<<echo = FALSE,message=FALSE,fig.align='center',fig.width=13,fig.height=11>>=
target_feature <- create_feature_target(40, 10, 25, 40)
tmp <- distr_crit(target = target_feature[,1], feature = target_feature[,2])
biogram:::ggplot2.criterion_distribution(tmp) + poster_theme
@
}
\column{.5\textwidth}
<<echo = FALSE,message=FALSE,results='asis'>>=
tab <- data.frame(table(target_feature[, 1], target_feature[, 2]))
colnames(tab) <- c("Target", "Feature", "Freq")
xtable(tab, align = c("|c|ccc|"), )
@
    \end{columns}
    
    \end{block}
    \vfill
    
%     \begin{block}{Test power}
%     \centering
% \scalebox{0.95}{  
% <<echo = FALSE,message=FALSE,eval=FALSE,fig.align='center'>>=
% 
% three_n_power <- three_n_power[sapply(three_n_power, function(i) i[[6]][[3]][2]) > 150]
% 
% power <- Reduce("+", lapply(three_n_power, function(single_rep) {
%   #single replication dat
%   sr_dat <- do.call(rbind, lapply(single_rep, unlist))
%   sr_dat[, c(1, 3, 5)]/matrix(rep(c(4, 32, 192), 6), nrow = 6, byrow = TRUE)
% }))/length(three_n_power)
% 
% ggplot(tfres(power), aes(x = ngram, y = value, fill = sig)) + 
%   geom_bar(stat = "identity", position = "dodge") +
%   scale_y_continuous("Important features found (%)") +
%   scale_x_discrete("n-gram") +
%   scale_fill_discrete("Signal strength") +
%   poster_theme
% 
% 
% @
% }
% \end{block}
%     \vfill

\begin{block}{Simulation scheme - genomics}
\begin{enumerate}[1.]
\item Random 4000 sequences (20 nucleotides each). The half of the sequences has label 0.
\item Choose a single position between 3 and 18 (to avoid border cases).
\item Resample nucleotides at chosen position. The dominant nucletoide has probabilitiy of occurence $p_d = 0.25$. Other nucleotides have probability of occurence $p_o = (1 - p_d)/3  $. 
\item Perform QuiPT (Information Gain as test statistic) and choose significant features (with p-value $< 0.001$).
\item Iterate steps 1-4 over other values of $p_d$ - 0.38, 0.51, 0.65, 0.78, 0.91.
\item Repeat steps 1-5 200 times.
\end{enumerate}
    \end{block}
    \vfill

\begin{block}{Power and False discoveries}
    \centering
\scalebox{1}{  
<<echo = FALSE,message=FALSE,fig.align='center', fig.width=15>>=
three_n_power <- three_n_power[sapply(three_n_power, function(i) i[[6]][[3]][2]) > 150]

power <- Reduce("+", lapply(three_n_power, function(single_rep) {
  #single replication dat
  sr_dat <- do.call(rbind, lapply(single_rep, unlist))
  sr_dat[, c(1, 3, 5)]/matrix(rep(c(4, 32, 192), 6), nrow = 6, byrow = TRUE)
}))/length(three_n_power)

mean_nonan <- function(x) {
  sum(x[!is.nan(x)])/sum(!is.nan(x))
  x[is.nan(x)] <- 0
  mean(x)
}

fs_dat <- sapply(three_n_power, function(single_rep) {
  #single replication dat
  sr_dat <- do.call(rbind, lapply(single_rep, unlist))
  (sr_dat[, c(2, 4, 6)] - sr_dat[, c(1, 3, 5)])/sr_dat[, c(2, 4, 6)]
})

fs_mean <- matrix(apply(fs_dat, 1, mean_nonan), nrow = 6)

#no significant features at all
no_sig <- matrix(apply(fs_dat, 1, function(i)
  sum(is.nan(i))), nrow = 6)

fs <- data.frame(tfres(fs_mean), 
                 no_sig = (length(three_n_power) - tfres(no_sig)[["value"]])/length(three_n_power),
                 power=tfres(power)$value)
#making signal strength number from range [0,1]
#fs$sig <- as.factor((as.numeric(fs$sig)-1)/5) 

p <- ggplot(fs, aes(x = ngram, y = sig, fill = power)) + 
  geom_tile() +
  scale_fill_continuous(name = "Power",
                        high = "#00CC00", low =  "#CCFFCC") +
  geom_point(aes(x = ngram, y = sig, size = value), range = c(5, 12)) +
  scale_size_continuous("False significant \nfeature frequency") +
  ylab(expression(paste("Signal strength - ", p[d]))) + xlab("n-gram size") +
  poster_theme
p +   geom_abline(intercept=1.5, slope=0.0, color="#666666", size=5) 


@
}

    
    \end{block}
    \vfill
      
     
    \begin{block}{Summary}
      Quick permutation test is a powerful and quick equivalent of permutation test in binary feature-binary target testing scenario.
    \end{block}
    \vfill 
    
        \begin{block}{Avaibility}
        \footnotesize{
      
      QuiPT is a part of biogram R package devoted to the analysis of n-grams extracted from biological sequences: 
      
      \url{http://cran.r-project.org/web/packages/biogram/}
        }
    \end{block}
    \vfill 
     
     
    \begin{block}{Bibliography}
    \tiny{
      \bibliographystyle{apalike}
      \bibliography{biogram_poster}
    }
    \end{block}
    \vfill
            }
        \end{minipage}
      \end{beamercolorbox}
    \end{column}
  \end{columns}  
\end{frame}
\end{document}